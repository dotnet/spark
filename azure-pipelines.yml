# Spark .NET build

trigger:
  batch: true
  branches:
    include:
    - master

variables:
  buildConfiguration: 'Release'
  _SignType: real
  _TeamName: DotNetSpark
  MSBUILDSINGLELOADCONTEXT: 1
  # backwardCompatibleRelease/forwardCompatibleRelease is the "oldest" releases that work with the current release
  backwardCompatibleRelease: '0.9.0'
  forwardCompatibleRelease: '0.9.0'
  TestsToFilterOut: "(FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.DataFrameTests.TestDataFrameGroupedMapUdf)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.DataFrameTests.TestDataFrameVectorUdf)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestDestroy)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestMultipleBroadcastWithoutEncryption)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestUnpersist)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.UdfTests.UdfSimpleTypesTests.TestUdfWithReturnAsTimestampType)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.UdfTests.UdfSimpleTypesTests.TestUdfWithTimestampType)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.SparkSessionTests.TestCreateDataFrameWithTimestamp)"
  LatestDotnetWorkerDir: '$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Worker\netcoreapp3.1\win-x64'
  BackwardCompatibleDotnetWorkerDir: $(Build.BinariesDirectory)\Microsoft.Spark.Worker-$(backwardCompatibleRelease)

  # Azure DevOps variables are transformed into environment variables, with these variables we
  # avoid the first time experience and telemetry to speed up the build.
  DOTNET_CLI_TELEMETRY_OPTOUT: 1
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1

resources:
  repositories:
  - repository: forwardCompatibleRelease
    type: github
    endpoint: dotnet
    name: dotnet/spark
    ref: refs/tags/v$(forwardCompatibleRelease)

jobs:
- job: Build
  displayName: Build and Test Sources
  pool: Hosted VS2017

  variables:
    ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
      _OfficialBuildIdArgs: /p:OfficialBuildId=$(BUILD.BUILDNUMBER)
    HADOOP_HOME: $(Build.BinariesDirectory)\hadoop

  steps:
  - checkout: self
    path: s\master
  - checkout: forwardCompatibleRelease
    path: s\$(forwardCompatibleRelease)

  - task: Maven@3
    displayName: 'Maven build src'
    inputs:
      mavenPomFile: master/src/scala/pom.xml

  - task: Maven@3
    displayName: 'Maven build benchmark'
    inputs:
      mavenPomFile: master/benchmark/scala/pom.xml

  - task: BatchScript@1
    displayName: Download Spark Distros & Winutils.exe
    inputs:
      filename: master\script\download-spark-distros.cmd
      arguments: $(Build.BinariesDirectory)

  - task: BatchScript@1
    displayName: Download backward compatible worker v$(backwardCompatibleRelease)
    inputs:
      filename: master\script\download-worker-release.cmd
      arguments: '$(Build.BinariesDirectory) $(backwardCompatibleRelease)'

  - script: master\build.cmd -pack
              -c $(buildConfiguration)
              -ci
              $(_OfficialBuildIdArgs)
              /p:PublishSparkWorker=true
              /p:SparkWorkerPublishDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Worker
    displayName: '.NET build'

  - task: DotNetCoreCLI@2
    displayName: '.NET unit tests'
    inputs:
      command: test
      projects: 'master/**/*UnitTest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.0'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.1'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.2'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.2-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.3'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.4'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.0'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.1'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)
  
  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.3'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.4'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.5'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.5-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.0 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.1 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.2 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.2-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.3 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.4 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.0 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.1 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)
  
  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.3 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.4 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.5 with backward compatible worker v$(backwardCompatibleRelease)'
    inputs:
      command: test
      projects: 'master/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.5-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

  - task: Maven@3
    displayName: 'Maven build src for forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      mavenPomFile: $(forwardCompatibleRelease)/src/scala/pom.xml
      
  - script: $(forwardCompatibleRelease)\build.cmd -pack
              -c $(buildConfiguration)
              -ci
              $(_OfficialBuildIdArgs)
              /p:PublishSparkWorker=true
              /p:SparkWorkerPublishDir=$(Build.ArtifactStagingDirectory)\$(forwardCompatibleRelease)\Microsoft.Spark.Worker
    displayName: '.NET build for forward compatible release v$(forwardCompatibleRelease)'

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.0 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.1 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.2 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.2-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.3 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.3.4 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.0 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.0-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.1 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.1-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)
  
  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.3 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.3-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.4 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.4-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - task: DotNetCoreCLI@2
    displayName: 'E2E tests for Spark 2.4.5 from forward compatible release v$(forwardCompatibleRelease)'
    inputs:
      command: test
      projects: '$(forwardCompatibleRelease)/**/Microsoft.Spark*.E2ETest/*.csproj'
      arguments: '--configuration $(buildConfiguration)'
    env:
      SPARK_HOME: $(Build.BinariesDirectory)\spark-2.4.5-bin-hadoop2.7
      DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

  - ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
    - task: CopyFiles@2
      displayName: Stage .NET artifacts
      inputs:
        sourceFolder: $(Build.SourcesDirectory)/master/artifacts/packages/$(buildConfiguration)/Shipping
        contents: |
          **/*.nupkg
          **/*.snupkg
        targetFolder: $(Build.ArtifactStagingDirectory)/BuildArtifacts/artifacts/packages/$(buildConfiguration)/Shipping

    - task: PublishBuildArtifacts@1
      inputs:
        pathtoPublish: '$(Build.ArtifactStagingDirectory)'
        artifactName:  Microsoft.Spark.Binaries

- ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
  - job: SignPublish
    dependsOn:
      - Build
    displayName: Sign and Publish Artifacts
    pool:
      name: NetCoreInternal-Pool
      queue: buildpool.windows.10.amd64.vs2017

    variables:
      ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
        _OfficialBuildIdArgs: /p:OfficialBuildId=$(BUILD.BUILDNUMBER)

    steps:
    - task: DownloadBuildArtifacts@0
      displayName: Download Build Artifacts
      inputs:
        artifactName: Microsoft.Spark.Binaries
        downloadPath: $(Build.ArtifactStagingDirectory)
    
    - task: MicroBuildSigningPlugin@2
      displayName: Install MicroBuild plugin
      inputs:
        signType: $(_SignType)
        zipSources: false
        feedSource: https://dnceng.pkgs.visualstudio.com/_packaging/MicroBuildToolset/nuget/v3/index.json
      env:
        TeamName: $(_TeamName)
      condition: and(succeeded(), in(variables['_SignType'], 'real', 'test'), eq(variables['Agent.Os'], 'Windows_NT'))
    
    - task: PowerShell@2
      displayName: Sign artifacts and Package Microsoft.Spark.Worker
      inputs:
        filePath: eng\common\build.ps1
        arguments: -restore -sign -publish
                   -c $(buildConfiguration)
                   -ci
                   $(_OfficialBuildIdArgs)
                   /p:DotNetSignType=$(_SignType)
                   /p:SparkPackagesDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Binaries\BuildArtifacts\artifacts\packages
                   /p:SparkWorkerPublishDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Binaries\Microsoft.Spark.Worker
                   /p:SparkWorkerPackageOutputDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Binaries

    - task: PublishBuildArtifacts@1
      inputs:
        pathtoPublish: '$(Build.ArtifactStagingDirectory)/Microsoft.Spark.Binaries'
        artifactName:  Microsoft.Spark.Binaries
