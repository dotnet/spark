   # Spark .NET build

trigger:
  batch: true
  branches:
    include:
    - master

variables:
  buildConfiguration: 'Release'
  _SignType: real
  _TeamName: DotNetSpark
  MSBUILDSINGLELOADCONTEXT: 1
  # backwardCompatibleRelease/forwardCompatibleRelease is the "oldest" releases that work with the current release
  backwardCompatibleRelease: '0.9.0'
  forwardCompatibleRelease: '0.9.0'
  TestsToFilterOut: "(FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.DataFrameTests.TestDataFrameGroupedMapUdf)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.DataFrameTests.TestDataFrameVectorUdf)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestDestroy)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestMultipleBroadcastWithoutEncryption)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.BroadcastTests.TestUnpersist)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.UdfTests.UdfSimpleTypesTests.TestUdfWithReturnAsTimestampType)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.UdfTests.UdfSimpleTypesTests.TestUdfWithTimestampType)&\
  (FullyQualifiedName!=Microsoft.Spark.E2ETest.IpcTests.SparkSessionTests.TestCreateDataFrameWithTimestamp)"
  LatestDotnetWorkerDir: '$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Worker\netcoreapp3.1\win-x64'
  BackwardCompatibleDotnetWorkerDir: $(Build.BinariesDirectory)\Microsoft.Spark.Worker-$(backwardCompatibleRelease)

  # Azure DevOps variables are transformed into environment variables, with these variables we
  # avoid the first time experience and telemetry to speed up the build.
  DOTNET_CLI_TELEMETRY_OPTOUT: 1
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1

resources:
  repositories:
  - repository: forwardCompatibleRelease
    type: github
    endpoint: dotnet
    name: dotnet/spark
    ref: refs/tags/v$(forwardCompatibleRelease)

stages:
- stage: Build
  jobs:
  - job: Build
    displayName: Build and Test Sources
    pool: Hosted VS2017

    variables:
      ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
        _OfficialBuildIdArgs: /p:OfficialBuildId=$(BUILD.BUILDNUMBER)
      HADOOP_HOME: $(Build.BinariesDirectory)\hadoop

    steps:
    - task: Maven@3
      displayName: 'Maven build src'
      inputs:
        mavenPomFile: src/scala/pom.xml

    - task: Maven@3
      displayName: 'Maven build benchmark'
      inputs:
        mavenPomFile: benchmark/scala/pom.xml

    - task: BatchScript@1
      displayName: Download Spark Distros & Winutils.exe
      inputs:
        filename: script\download-spark-distros.cmd
        arguments: $(Build.BinariesDirectory)

    - script: build.cmd -pack
                -c $(buildConfiguration)
                -ci
                $(_OfficialBuildIdArgs)
                /p:PublishSparkWorker=true
                /p:SparkWorkerPublishDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Worker
      displayName: '.NET build'

    - task: DotNetCoreCLI@2
      displayName: '.NET unit tests'
      inputs:
        command: test
        projects: '**/*UnitTest/*.csproj'
        arguments: '--configuration $(buildConfiguration)'

    - task: DotNetCoreCLI@2
      displayName: 'E2E tests for Spark 2.3.0'
      inputs:
        command: test
        projects: '**/Microsoft.Spark.E2ETest/*.csproj'
        arguments: '--configuration $(buildConfiguration)'
      env:
        SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
        DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)

- stage: BackwardCompatibility
  dependsOn: Build
  jobs:
  - job: BackwardCompatibility
    # displayName: Build and Test Sources
    pool: Hosted VS2017

    variables:
      ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
        _OfficialBuildIdArgs: /p:OfficialBuildId=$(BUILD.BUILDNUMBER)
      HADOOP_HOME: $(Build.BinariesDirectory)\hadoop

    steps:
    - task: Maven@3
      displayName: 'Maven build src'
      inputs:
        mavenPomFile: src/scala/pom.xml

    - task: BatchScript@1
      displayName: Download Spark Distros & Winutils.exe
      inputs:
        filename: script\download-spark-distros.cmd
        arguments: $(Build.BinariesDirectory)

    - task: BatchScript@1
      displayName: Download backward compatible worker v$(backwardCompatibleRelease)
      inputs:
        filename: script\download-worker-release.cmd
        arguments: '$(Build.BinariesDirectory) $(backwardCompatibleRelease)'

    - script: build.cmd
                -c $(buildConfiguration)
                -ci
                $(_OfficialBuildIdArgs)
                /p:PublishSparkWorker=false
      displayName: '.NET build for backward compatible release v$(backwardCompatibleRelease)'

    - task: DotNetCoreCLI@2
      displayName: 'E2E tests for Spark 2.3.0 with backward compatible worker v$(backwardCompatibleRelease)'
      inputs:
        command: test
        projects: '**/Microsoft.Spark.E2ETest/*.csproj'
        arguments: '--configuration $(buildConfiguration) --filter $(TestsToFilterOut)'
      env:
        SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
        DOTNET_WORKER_DIR: $(BackwardCompatibleDotnetWorkerDir)

- stage: ForwardCompatibility
  dependsOn: Build
  jobs:
  - job: ForwardCompatibility
    # displayName: Build and Test Sources
    pool: Hosted VS2017

    variables:
      ${{ if and(ne(variables['System.TeamProject'], 'public'), notin(variables['Build.Reason'], 'PullRequest')) }}:
        _OfficialBuildIdArgs: /p:OfficialBuildId=$(BUILD.BUILDNUMBER)
      HADOOP_HOME: $(Build.BinariesDirectory)\hadoop

    steps:
    - checkout: self
      path: s\master
    - checkout: forwardCompatibleRelease
      path: s\$(forwardCompatibleRelease)
    
    - task: Maven@3
      displayName: 'Maven build src for forward compatible release v$(forwardCompatibleRelease)'
      inputs:
        mavenPomFile: $(forwardCompatibleRelease)/src/scala/pom.xml
      
    - task: BatchScript@1
      displayName: Download Spark Distros & Winutils.exe
      inputs:
        filename: master\script\download-spark-distros.cmd
        arguments: $(Build.BinariesDirectory)

    - script: $(forwardCompatibleRelease)\build.cmd
                -c $(buildConfiguration)
                -ci
                $(_OfficialBuildIdArgs)
                /p:PublishSparkWorker=false
      displayName: '.NET build for forward compatible release v$(forwardCompatibleRelease)'

    - script: master\build.cmd -pack
                -c $(buildConfiguration)
                -ci
                $(_OfficialBuildIdArgs)
                /p:PublishSparkWorker=true
                /p:SparkWorkerPublishDir=$(Build.ArtifactStagingDirectory)\Microsoft.Spark.Worker
      displayName: '.NET build'

    - task: DotNetCoreCLI@2
      displayName: 'E2E tests for Spark 2.3.0 from forward compatible release v$(forwardCompatibleRelease)'
      inputs:
        command: test
        projects: '**/Microsoft.Spark.E2ETest/*.csproj'
        arguments: '--configuration $(buildConfiguration)'
      env:
        SPARK_HOME: $(Build.BinariesDirectory)\spark-2.3.0-bin-hadoop2.7
        DOTNET_WORKER_DIR: $(LatestDotnetWorkerDir)