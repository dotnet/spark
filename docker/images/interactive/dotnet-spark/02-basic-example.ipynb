{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic .NET for Apache Spark example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Start the Backend in Debug mode\n",
    "\n",
    "**_Important_**: Before you run any cells in this example, please ensure that you have [started the .NET for Apache Spark DotnetBacken in Debug mode](01-start-spark-debug.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Microsoft.Spark NuGet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.Spark,1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Coding\n",
    "\n",
    "### Create a new SparkSession\n",
    "The entry point to all .NET for Apache Spark functionality is a SparkSession. To create one, just use SparkSession.Builder():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Microsoft.Spark.Sql;\n",
    "using Microsoft.Spark.Sql.Types;\n",
    "using static Microsoft.Spark.Sql.Functions;\n",
    "\n",
    "var spark = SparkSession.Builder().GetOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new DataFrame\n",
    "There are multiple ways of creating new DataFrames. Most of the time you will read data from another source. For this basic example, we just define our DataFrame via the code below, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var data = new List<GenericRow>\n",
    "    {\n",
    "        new GenericRow(new object[] { \"Batman\", \"M\", 3093, true, new Date(1939, 5, 1) }),\n",
    "        new GenericRow(new object[] { \"Superman\", \"M\", 2496, true, new Date(1986, 10, 1) }),\n",
    "        new GenericRow(new object[] { \"Wonder Woman\", \"F\", 1231, true, new Date(1941, 12, 1) }),\n",
    "        new GenericRow(new object[] { \"Lois Lane\", \"F\", 934, true, new Date(1938, 6, 1) })\n",
    "    };\n",
    "\n",
    "var schema = new StructType(new List<StructField>()\n",
    "    {\n",
    "        new StructField(\"Name\", new StringType()),\n",
    "        new StructField(\"Sex\", new StringType()),\n",
    "        new StructField(\"Appearances\", new IntegerType()),\n",
    "        new StructField(\"Alive\", new BooleanType()),\n",
    "        new StructField(\"FirstAppearance\", new DateType())\n",
    "    });\n",
    "\n",
    "DataFrame df = spark.CreateDataFrame(data, schema);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a quick overview of your data\n",
    "\n",
    "To verify/display the Spark data types of a DataFrame use **PrintSchema()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PrintSchema();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **Show()** to have a look at the first couple of rows of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some basic DataFrame statistics, use **Describe()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Describe().Show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column style filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Filter(df.Col(\"Name\") == \"Batman\").Show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Filter(df[\"Appearances\"] > 1000).Show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL style Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Filter(\"Sex == 'F'\").Show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Filter(\"FirstAppearance >= '1971-01-01'\").Show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Filter(\"Name not like '%man'\").Show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GroupBy(\"Sex\").Count().Show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GroupBy(\"Sex\")\n",
    "    .Agg(Count(df[\"Sex\"]), Avg(df[\"Appearances\"]), Min(df[\"Appearances\"]), Max(df[\"Appearances\"]))\n",
    "    .OrderBy(Desc(\"avg(Appearances)\"))\n",
    "    .Show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Stop your spark session, once you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.Stop();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
